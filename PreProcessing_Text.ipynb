{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PreProcessing Text.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMDw6iES+pWjB/drND/SfZA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejashreeSalvi/Github-tut/blob/dev/PreProcessing_Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdQAmBtHAP--",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f89105ee-e0cf-4705-f365-d0fd6fcb4512"
      },
      "source": [
        "!pip install pyspellchecker"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.6/dist-packages (0.5.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWt2Db6pA_GZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1dca5348-bc30-4763-f1b3-6b9a857c70a8"
      },
      "source": [
        "!apt install -qq enchant --upgrade\n",
        "!pip install pyenchant --upgrade"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  aspell aspell-en dictionaries-common emacsen-common hunspell-en-us\n",
            "  libaspell15 libenchant1c2a libhunspell-1.6-0 libtext-iconv-perl\n",
            "Suggested packages:\n",
            "  aspell-doc spellutils wordlist hunspell openoffice.org-hunspell\n",
            "  | openoffice.org-core libenchant-voikko\n",
            "The following NEW packages will be installed:\n",
            "  aspell aspell-en dictionaries-common emacsen-common enchant hunspell-en-us\n",
            "  libaspell15 libenchant1c2a libhunspell-1.6-0 libtext-iconv-perl\n",
            "0 upgraded, 10 newly installed, 0 to remove and 59 not upgraded.\n",
            "Need to get 1,310 kB of archives.\n",
            "After this operation, 5,353 kB of additional disk space will be used.\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package libtext-iconv-perl.\n",
            "(Reading database ... 144328 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libtext-iconv-perl_1.7-5build6_amd64.deb ...\n",
            "Unpacking libtext-iconv-perl (1.7-5build6) ...\n",
            "Selecting previously unselected package libaspell15:amd64.\n",
            "Preparing to unpack .../1-libaspell15_0.60.7~20110707-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking libaspell15:amd64 (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Selecting previously unselected package emacsen-common.\n",
            "Preparing to unpack .../2-emacsen-common_2.0.8_all.deb ...\n",
            "Unpacking emacsen-common (2.0.8) ...\n",
            "Selecting previously unselected package dictionaries-common.\n",
            "Preparing to unpack .../3-dictionaries-common_1.27.2_all.deb ...\n",
            "Adding 'diversion of /usr/share/dict/words to /usr/share/dict/words.pre-dictionaries-common by dictionaries-common'\n",
            "Unpacking dictionaries-common (1.27.2) ...\n",
            "Selecting previously unselected package aspell.\n",
            "Preparing to unpack .../4-aspell_0.60.7~20110707-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking aspell (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Selecting previously unselected package aspell-en.\n",
            "Preparing to unpack .../5-aspell-en_2017.08.24-0-0.1_all.deb ...\n",
            "Unpacking aspell-en (2017.08.24-0-0.1) ...\n",
            "Selecting previously unselected package hunspell-en-us.\n",
            "Preparing to unpack .../6-hunspell-en-us_1%3a2017.08.24_all.deb ...\n",
            "Unpacking hunspell-en-us (1:2017.08.24) ...\n",
            "Selecting previously unselected package libhunspell-1.6-0:amd64.\n",
            "Preparing to unpack .../7-libhunspell-1.6-0_1.6.2-1_amd64.deb ...\n",
            "Unpacking libhunspell-1.6-0:amd64 (1.6.2-1) ...\n",
            "Selecting previously unselected package libenchant1c2a:amd64.\n",
            "Preparing to unpack .../8-libenchant1c2a_1.6.0-11.1_amd64.deb ...\n",
            "Unpacking libenchant1c2a:amd64 (1.6.0-11.1) ...\n",
            "Selecting previously unselected package enchant.\n",
            "Preparing to unpack .../9-enchant_1.6.0-11.1_amd64.deb ...\n",
            "Unpacking enchant (1.6.0-11.1) ...\n",
            "Setting up libhunspell-1.6-0:amd64 (1.6.2-1) ...\n",
            "Setting up libaspell15:amd64 (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Setting up emacsen-common (2.0.8) ...\n",
            "Setting up libtext-iconv-perl (1.7-5build6) ...\n",
            "Setting up dictionaries-common (1.27.2) ...\n",
            "Setting up aspell (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Setting up hunspell-en-us (1:2017.08.24) ...\n",
            "Setting up libenchant1c2a:amd64 (1.6.0-11.1) ...\n",
            "Setting up aspell-en (2017.08.24-0-0.1) ...\n",
            "Setting up enchant (1.6.0-11.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for dictionaries-common (1.27.2) ...\n",
            "aspell-autobuildhash: processing: en [en-common].\n",
            "aspell-autobuildhash: processing: en [en-variant_0].\n",
            "aspell-autobuildhash: processing: en [en-variant_1].\n",
            "aspell-autobuildhash: processing: en [en-variant_2].\n",
            "aspell-autobuildhash: processing: en [en-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_AU-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_AU-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_AU-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_AU-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_CA-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_CA-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_CA-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_CA-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ise-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ise-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ize-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ize-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_GB-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_US-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_US-wo_accents-only].\n",
            "Requirement already up-to-date: pyenchant in /usr/local/lib/python3.6/dist-packages (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNZotrxYCHNY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "dbac2d76-6112-4d6d-e136-2c6438ea0e44"
      },
      "source": [
        "!pip install googletrans"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.6/dist-packages (3.0.0)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.6/dist-packages (from googletrans) (0.13.3)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (0.9.1)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (2.9)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (1.1.0)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (2020.6.23)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (2020.6.20)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (1.4.0)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.6/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.6/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)\n",
            "Requirement already satisfied: contextvars>=2.1; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from sniffio->httpx==0.13.3->googletrans) (2.4)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.6/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.6/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)\n",
            "Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars>=2.1; python_version < \"3.7\"->sniffio->httpx==0.13.3->googletrans) (0.14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTXub20ZBjkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spellchecker import SpellChecker\n",
        "import re\n",
        "import string\n",
        "import enchant\n",
        "from googletrans import Translator\n",
        "\n",
        "d = enchant.Dict(\"en_US\")"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z48YAUQaASc7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Replacint multiple repeating letters by 2 repeating letters \n",
        "def replace(s, list1): \n",
        "    new_str = []\n",
        "    for ch in list1:# itterate = 4\n",
        "        new_str = []\n",
        "        l = len(s) #length of s = 21\n",
        "        for i in range(len(s)):\n",
        "            if (s[i] == ch and i != (l - 1) and\n",
        "                    i != 0 and s[i + 1] != ch and s[i - 1] != ch):\n",
        "                new_str.append(s[i])\n",
        "            # to reduce multiple chars to double\n",
        "            elif s[i] == ch:\n",
        "                if ((i != (l - 1) and s[i + 1] == ch) and\n",
        "                        (i != 0 and s[i - 2] != ch)):\n",
        "                    new_str.append(s[i])\n",
        "            else:\n",
        "                new_str.append(s[i])\n",
        " \n",
        "        s = new_str\n",
        " \n",
        "    return \"\".join(i for i in new_str)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g7xuXa9Cv-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Detemining the duplicate letters in words\n",
        "def duplicate(string):\n",
        "    # list to store duplicate characters\n",
        "    list = []\n",
        "    #print(\"Duplicate characters in a given string: \")\n",
        "    # loop counts each character present in the string\n",
        "    for i in range(0, len(string)):\n",
        "        count = 1\n",
        "        for j in range(i + 1, len(string)):\n",
        "            if string[i] == string[j] and string[i] != ' ':\n",
        "                count = count + 1\n",
        "                # Set string[j] to 0 to avoid printing visited character\n",
        "                string = string[:j] + '0' + string[j + 1:]\n",
        "                # A character considered as duplicate if count is greater than 3\n",
        "        if count >= 3 and string[i] != '0':\n",
        "            list.append((string[i]))\n",
        "    if(len(list)==0):\n",
        "        return list\n",
        "    else:\n",
        "        return list\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNjMaTyIC8tu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Analysing the repeated words for english word\n",
        "def reduceRepetition(RefinedStatements):\n",
        "    tempList = re.split('\\s+',RefinedStatements)\n",
        "    reducedString = \"\"\n",
        "    newList = \"\"\n",
        "    tempString = \"\"\n",
        "    for i in range(len(tempList)):\n",
        "        newList = duplicate(tempList[i])\n",
        "        if(len(newList)!=0):\n",
        "            reducedString = replace(tempList[i],newList)\n",
        "#            print('The reduced string is :',reducedString)\n",
        "            #z = translator.translate(reducedString,src = 'en',dest = 'en').text\n",
        "            #z = TextBlob(reducedString)\n",
        "            #z = z.correct()\n",
        "            z = spell.correction(reducedString)\n",
        " #           print('Transliteration : ',z)\n",
        "            if(d.check(z)):\n",
        "                reducedString = z;\n",
        "        else:\n",
        "            reducedString = tempList[i]\n",
        "  #          print('The reduced NON CHANGED string is :',reducedString)\n",
        "        tempString = tempString + reducedString + \" \"\n",
        "    return tempString"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqO47wG_EZeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(lst): \n",
        "    return ' '.join(lst).split() "
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQpcimuUASQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "spell = SpellChecker()\n",
        "translator = Translator()\n",
        "\n",
        "def TranslationFunction(sentences):\n",
        "    \n",
        "    # Remove the more occurences of alphabets...\n",
        "    formattedSentence = reduceRepetition(sentences)\n",
        "    print(\"Sakshi Model Output :: \"+formattedSentence)\n",
        "    \n",
        "    # Split the list...\n",
        "    lst2 = convert([formattedSentence])\n",
        "    print(\"Split List\"+str(lst2))\n",
        "    \n",
        "    # Declare List..\n",
        "    List = [];\n",
        "    # iterate over Split List..\n",
        "    for word in lst2:\n",
        "        print(\"\\n\")\n",
        "        print(word)\n",
        "        print(translator.detect(word))\n",
        "        #Detect the lang of each word and check the spelling, correct it..\n",
        "        if((translator.detect(word).confidence) >= 0.90 and (translator.detect(word).lang) == 'en'):\n",
        "            word = spell.correction(word);\n",
        "            print(\"Spelling Correction:\"+word);\n",
        "        \n",
        "        # Append all the word in List...\n",
        "        List.append(word)\n",
        "\n",
        "    # Convert List to String ie. Sentence.\n",
        "    listToStr = ' '.join(map(str, List)) \n",
        "    print(\"Hello1\");\n",
        "    print(List)\n",
        "\n",
        "    lang = translator.detect(listToStr).lang;\n",
        "    print(\"Language Detected : \"+lang);\n",
        "    # convert into destination languages.\n",
        "    if(lang != 'en'):\n",
        "        print(\"Sentence is not in English, need to convert it..\")\n",
        "        print(\"Hello2\");\n",
        "        hindiString = translator.translate(listToStr,dest=translator.detect(listToStr).lang).text\n",
        "        print(\"Language Text: \"+hindiString);\n",
        "        # Convert into English\n",
        "        print(\"Hello3\");\n",
        "        listToStr = translator.translate(hindiString, dest=\"en\").text\n",
        "    print(listToStr)\n",
        "    return listToStr;"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKmQISTkAnBQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d9550f1-bcc2-499a-ca2a-0465c86518e6"
      },
      "source": [
        "sent_english_array = [\"hhhhhhhheyyyyyyyy hhhhoooooooowwwww are youuuuuuuuu, kaha tha itne dinon se ? I really miss yooooooooou yaar...\",\"Heelllo, Howww Are youu?\",\"yea let me just pay 600 dollars for phone so it dies at 30% fix your shit @apple\",\"Hello, Cambridge restaurant system mein aapka swagat hai. Aap pa sakte hai restaurant by area, price range ya food type. Aap ko kaise help kar sakta hu main ?\"]\n",
        "for s in sent_english_array:\n",
        "    print(\"\\n**********************Sentence Input :::\"+s);\n",
        "    print(\"********************Final Output::: \"+TranslationFunction(str(s)))\n",
        "\n",
        "# TranslationFunction(\"hhhhhhhheyyyyyyyy hhhhoooooooowwwww are youuuuuuuuu, kaha tha itne dinon se ? I really miss yooooooooou yaar...\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "**********************Sentence Input :::hhhhhhhheyyyyyyyy hhhhoooooooowwwww are youuuuuuuuu, kaha tha itne dinon se ? I really miss yooooooooou yaar...\n",
            "Sakshi Model Output :: hey how are you kaha tha itne dinon se ? I really miss you yaar.. \n",
            "Split List['hey', 'how', 'are', 'you', 'kaha', 'tha', 'itne', 'dinon', 'se', '?', 'I', 'really', 'miss', 'you', 'yaar..']\n",
            "\n",
            "\n",
            "hey\n",
            "Detected(lang=en, confidence=0.9545455)\n",
            "Spelling Correction:hey\n",
            "\n",
            "\n",
            "how\n",
            "Detected(lang=en, confidence=0.9635417)\n",
            "Spelling Correction:how\n",
            "\n",
            "\n",
            "are\n",
            "Detected(lang=en, confidence=1.0)\n",
            "Spelling Correction:are\n",
            "\n",
            "\n",
            "you\n",
            "Detected(lang=en, confidence=0.9427083)\n",
            "Spelling Correction:you\n",
            "\n",
            "\n",
            "kaha\n",
            "Detected(lang=hi, confidence=1.0)\n",
            "\n",
            "\n",
            "tha\n",
            "Detected(lang=el, confidence=0.859375)\n",
            "\n",
            "\n",
            "itne\n",
            "Detected(lang=sv, confidence=0.8171206)\n",
            "\n",
            "\n",
            "dinon\n",
            "Detected(lang=hi, confidence=1.0)\n",
            "\n",
            "\n",
            "se\n",
            "Detected(lang=es, confidence=0.21538459)\n",
            "\n",
            "\n",
            "?\n",
            "Detected(lang=en, confidence=0.0)\n",
            "\n",
            "\n",
            "I\n",
            "Detected(lang=en, confidence=0.77154034)\n",
            "\n",
            "\n",
            "really\n",
            "Detected(lang=en, confidence=1.0)\n",
            "Spelling Correction:really\n",
            "\n",
            "\n",
            "miss\n",
            "Detected(lang=en, confidence=0.9568151)\n",
            "Spelling Correction:miss\n",
            "\n",
            "\n",
            "you\n",
            "Detected(lang=en, confidence=0.9427083)\n",
            "Spelling Correction:you\n",
            "\n",
            "\n",
            "yaar..\n",
            "Detected(lang=ta, confidence=0.8464567)\n",
            "Hello1\n",
            "['hey', 'how', 'are', 'you', 'kaha', 'tha', 'itne', 'dinon', 'se', '?', 'I', 'really', 'miss', 'you', 'yaar..']\n",
            "Language Detected : hi\n",
            "Sentence is not in English, need to convert it..\n",
            "Hello2\n",
            "Language Text: हे हाउ आर यू कहा था इतने दिनों से ? ी रियली मिस यू यार..\n",
            "Hello3\n",
            "Hey how were you these days? Mr. Really Miss You Man ..\n",
            "********************Final Output::: Hey how were you these days? Mr. Really Miss You Man ..\n",
            "\n",
            "**********************Sentence Input :::Heelllo, Howww Are youu?\n",
            "Sakshi Model Output :: hello how Are youu? \n",
            "Split List['hello', 'how', 'Are', 'youu?']\n",
            "\n",
            "\n",
            "hello\n",
            "Detected(lang=en, confidence=1.0)\n",
            "Spelling Correction:hello\n",
            "\n",
            "\n",
            "how\n",
            "Detected(lang=en, confidence=0.9635417)\n",
            "Spelling Correction:how\n",
            "\n",
            "\n",
            "Are\n",
            "Detected(lang=en, confidence=1.0)\n",
            "Spelling Correction:Are\n",
            "\n",
            "\n",
            "youu?\n",
            "Detected(lang=en, confidence=1.0)\n",
            "Spelling Correction:you\n",
            "Hello1\n",
            "['hello', 'how', 'Are', 'you']\n",
            "Language Detected : en\n",
            "hello how Are you\n",
            "********************Final Output::: hello how Are you\n",
            "\n",
            "**********************Sentence Input :::yea let me just pay 600 dollars for phone so it dies at 30% fix your shit @apple\n",
            "Sakshi Model Output :: yea let me just pay 600 dollars for phone so it dies at 30% fix your shit @apple \n",
            "Split List['yea', 'let', 'me', 'just', 'pay', '600', 'dollars', 'for', 'phone', 'so', 'it', 'dies', 'at', '30%', 'fix', 'your', 'shit', '@apple']\n",
            "\n",
            "\n",
            "yea\n",
            "Detected(lang=en, confidence=1.0)\n",
            "Spelling Correction:yea\n",
            "\n",
            "\n",
            "let\n",
            "Detected(lang=en, confidence=0.8863937)\n",
            "\n",
            "\n",
            "me\n",
            "Detected(lang=en, confidence=0.7675033)\n",
            "\n",
            "\n",
            "just\n",
            "Detected(lang=en, confidence=0.9895833)\n",
            "Spelling Correction:just\n",
            "\n",
            "\n",
            "pay\n",
            "Detected(lang=en, confidence=1.0)\n",
            "Spelling Correction:pay\n",
            "\n",
            "\n",
            "600\n",
            "Detected(lang=en, confidence=0.0)\n",
            "\n",
            "\n",
            "dollars\n",
            "Detected(lang=en, confidence=0.9207792)\n",
            "Spelling Correction:dollars\n",
            "\n",
            "\n",
            "for\n",
            "Detected(lang=en, confidence=0.97016865)\n",
            "Spelling Correction:for\n",
            "\n",
            "\n",
            "phone\n",
            "Detected(lang=en, confidence=0.98941797)\n",
            "Spelling Correction:phone\n",
            "\n",
            "\n",
            "so\n",
            "Detected(lang=en, confidence=0.8843627)\n",
            "\n",
            "\n",
            "it\n",
            "Detected(lang=en, confidence=1.0)\n",
            "Spelling Correction:it\n",
            "\n",
            "\n",
            "dies\n",
            "Detected(lang=en, confidence=0.7163398)\n",
            "\n",
            "\n",
            "at\n",
            "Detected(lang=en, confidence=0.92317706)\n",
            "Spelling Correction:at\n",
            "\n",
            "\n",
            "30%\n",
            "Detected(lang=en, confidence=0.0)\n",
            "\n",
            "\n",
            "fix\n",
            "Detected(lang=en, confidence=0.948886)\n",
            "Spelling Correction:fix\n",
            "\n",
            "\n",
            "your\n",
            "Detected(lang=en, confidence=1.0)\n",
            "Spelling Correction:your\n",
            "\n",
            "\n",
            "shit\n",
            "Detected(lang=en, confidence=0.9891892)\n",
            "Spelling Correction:shit\n",
            "\n",
            "\n",
            "@apple\n",
            "Detected(lang=en, confidence=0.8675324)\n",
            "Hello1\n",
            "['yea', 'let', 'me', 'just', 'pay', '600', 'dollars', 'for', 'phone', 'so', 'it', 'dies', 'at', '30%', 'fix', 'your', 'shit', '@apple']\n",
            "Language Detected : en\n",
            "yea let me just pay 600 dollars for phone so it dies at 30% fix your shit @apple\n",
            "********************Final Output::: yea let me just pay 600 dollars for phone so it dies at 30% fix your shit @apple\n",
            "\n",
            "**********************Sentence Input :::Hello, Cambridge restaurant system mein aapka swagat hai. Aap pa sakte hai restaurant by area, price range ya food type. Aap ko kaise help kar sakta hu main ?\n",
            "Sakshi Model Output :: Hello, Cambridge restaurant system mein pk swagat hai. Aap pa sakte hai restaurant by area, price range ya food type. Aap ko kaise help kar sakta hu main ? \n",
            "Split List['Hello,', 'Cambridge', 'restaurant', 'system', 'mein', 'pk', 'swagat', 'hai.', 'Aap', 'pa', 'sakte', 'hai', 'restaurant', 'by', 'area,', 'price', 'range', 'ya', 'food', 'type.', 'Aap', 'ko', 'kaise', 'help', 'kar', 'sakta', 'hu', 'main', '?']\n",
            "\n",
            "\n",
            "Hello,\n",
            "Detected(lang=en, confidence=1.0)\n",
            "Spelling Correction:hello\n",
            "\n",
            "\n",
            "Cambridge\n",
            "Detected(lang=en, confidence=0.9650067)\n",
            "Spelling Correction:Cambridge\n",
            "\n",
            "\n",
            "restaurant\n",
            "Detected(lang=en, confidence=0.9116095)\n",
            "Spelling Correction:restaurant\n",
            "\n",
            "\n",
            "system\n",
            "Detected(lang=en, confidence=0.9868421)\n",
            "Spelling Correction:system\n",
            "\n",
            "\n",
            "mein\n",
            "Detected(lang=de, confidence=0.8515625)\n",
            "\n",
            "\n",
            "pk\n",
            "Detected(lang=en, confidence=0.7915007)\n",
            "\n",
            "\n",
            "swagat\n",
            "Detected(lang=hi, confidence=0.80078125)\n",
            "\n",
            "\n",
            "hai.\n",
            "Detected(lang=hi, confidence=0.41860464)\n",
            "\n",
            "\n",
            "Aap\n",
            "Detected(lang=hi, confidence=0.98828125)\n",
            "\n",
            "\n",
            "pa\n",
            "Detected(lang=sl, confidence=0.48046875)\n",
            "\n",
            "\n",
            "sakte\n",
            "Detected(lang=no, confidence=0.94921875)\n",
            "\n",
            "\n",
            "hai\n",
            "Detected(lang=hi, confidence=0.41860464)\n",
            "\n",
            "\n",
            "restaurant\n",
            "Detected(lang=en, confidence=0.9116095)\n",
            "Spelling Correction:restaurant\n",
            "\n",
            "\n",
            "by\n",
            "Detected(lang=en, confidence=1.0)\n",
            "Spelling Correction:by\n",
            "\n",
            "\n",
            "area,\n",
            "Detected(lang=en, confidence=0.98689383)\n",
            "Spelling Correction:area\n",
            "\n",
            "\n",
            "price\n",
            "Detected(lang=en, confidence=1.0)\n",
            "Spelling Correction:price\n",
            "\n",
            "\n",
            "range\n",
            "Detected(lang=en, confidence=1.0)\n",
            "Spelling Correction:range\n",
            "\n",
            "\n",
            "ya\n",
            "Detected(lang=sw, confidence=0.23137255)\n",
            "\n",
            "\n",
            "food\n",
            "Detected(lang=en, confidence=1.0)\n",
            "Spelling Correction:food\n",
            "\n",
            "\n",
            "type.\n",
            "Detected(lang=en, confidence=0.9656085)\n",
            "Spelling Correction:type\n",
            "\n",
            "\n",
            "Aap\n",
            "Detected(lang=hi, confidence=0.98828125)\n",
            "\n",
            "\n",
            "ko\n",
            "Detected(lang=tl, confidence=0.33590737)\n",
            "\n",
            "\n",
            "kaise\n",
            "Detected(lang=hi, confidence=1.0)\n",
            "\n",
            "\n",
            "help\n",
            "Detected(lang=en, confidence=1.0)\n",
            "Spelling Correction:help\n",
            "\n",
            "\n",
            "kar\n",
            "Detected(lang=slhi, confidence=0.503937)\n",
            "\n",
            "\n",
            "sakta\n",
            "Detected(lang=sq, confidence=0.80078125)\n",
            "\n",
            "\n",
            "hu\n",
            "Detected(lang=arzh-CN, confidence=0.578125)\n",
            "\n",
            "\n",
            "main\n",
            "Detected(lang=en, confidence=0.95926416)\n",
            "Spelling Correction:main\n",
            "\n",
            "\n",
            "?\n",
            "Detected(lang=en, confidence=0.0)\n",
            "Hello1\n",
            "['hello', 'Cambridge', 'restaurant', 'system', 'mein', 'pk', 'swagat', 'hai.', 'Aap', 'pa', 'sakte', 'hai', 'restaurant', 'by', 'area', 'price', 'range', 'ya', 'food', 'type', 'Aap', 'ko', 'kaise', 'help', 'kar', 'sakta', 'hu', 'main', '?']\n",
            "Language Detected : hi\n",
            "Sentence is not in English, need to convert it..\n",
            "Hello2\n",
            "Language Text: हेलो कैंब्रिज रेस्टोरेंट सिस्टम में पक स्वागत है. आप पा सकते है रेस्टोरेंट बय एरिया प्राइस रेंज या फ़ूड टाइप आप को कैसे हेल्प कर सकता हु मैं ?\n",
            "Hello3\n",
            "Puck Welcome to the Hello Cambridge Restaurant System. You can find restaurant buy area price range or food type. How can I help you?\n",
            "********************Final Output::: Puck Welcome to the Hello Cambridge Restaurant System. You can find restaurant buy area price range or food type. How can I help you?\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}